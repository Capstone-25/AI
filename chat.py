"""
ì‹¤í–‰ ì½”ë“œ
python chat.py --output_file results/result1.json --persona_type persona_20s_friend --chat_id chat101 --user_id user1234
"""

import json
from pathlib import Path
from agents.client_agent import ClientAgent
from agents.counselor_agent import CounselorAgent
from agents.evaluator_agent import EvaluatorAgent
from agents.sub_llm import SubLLMAgent
from config import get_config, set_openai_api_key
from cbt.cbt_mappings import emotion_strategies, cognitive_distortion_strategies
from DB import get_chat_log, save_chat_log, save_user_info, get_user_info

# --- STT ê´€ë ¨ ëª¨ë“ˆ ì¶”ê°€ ---
import whisper
import sounddevice as sd
import numpy as np
import wave
import keyboard  # pip install keyboard
import time

# ë§ˆì´í¬ë¡œ Enter ëˆ„ë¥´ë©´ ë…¹ìŒ ì‹œì‘, ë‹¤ì‹œ Enter ëˆ„ë¥´ë©´ ë…¹ìŒ ì¢…ë£Œ
def record_audio_keypress(filename="input.wav", fs=16000):
    print("âºï¸ Enter í‚¤ë¥¼ ëˆ„ë¥´ë©´ ë…¹ìŒ ì‹œì‘, ë‹¤ì‹œ ëˆ„ë¥´ë©´ ì¢…ë£Œ (2ì´ˆ ì´ìƒ ëˆ„ë¥´ë©´ ì±—ë´‡ ì¢…ë£Œ)")

    # Enter ëˆŒëŸ¬ì„œ ì‹œì‘
    while True:
        if keyboard.read_key() == "enter":
            print("ğŸ™ï¸ ë…¹ìŒ ì¤‘... ë‹¤ì‹œ Enter ëˆ„ë¥´ë©´ ì¢…ë£Œ")
            break

    recording = []
    stream = sd.InputStream(samplerate=fs, channels=1, dtype='int16')
    stream.start()

    # ì¢…ë£Œ ê°ì§€
    while True:
        if keyboard.is_pressed("enter"):
            start_time = time.time()
            while keyboard.is_pressed("enter"):
                time.sleep(0.1)
                if time.time() - start_time >= 2.0:
                    print("ğŸ›‘ Enter í‚¤ 2ì´ˆ ì´ìƒ ëˆ„ë¦„ â†’ ì±—ë´‡ ì¢…ë£Œ")
                    stream.stop()
                    stream.close()
                    return "exit"

            print("â¹ï¸ ë…¹ìŒ ì¢…ë£Œ")
            break

        data, _ = stream.read(1024)
        recording.append(data)

    stream.stop()
    stream.close()

    audio_data = np.concatenate(recording)
    with wave.open(filename, 'wb') as wf:
        wf.setnchannels(1)
        wf.setsampwidth(2)
        wf.setframerate(fs)
        wf.writeframes(audio_data.tobytes())

    print("âœ… ì €ì¥ ì™„ë£Œ:", filename)
    return "ok"

# Whisperë¡œ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
def whisper_transcribe(filename="input.wav"):
    model = whisper.load_model("base")
    result = model.transcribe(filename, language='ko')
    return result["text"]

# OpenAI API í‚¤ ì„¤ì •
set_openai_api_key()

# MongoDB ì—°ê²°
from pymongo import MongoClient
client = MongoClient("mongodb+srv://j2982477:EZ6t7LEsGEYmCiJK@mindAI.zgcb4ae.mongodb.net/?retryWrites=true&w=majority&appName=mindAI")
db = client['mindAI']


# TherapySimulation í´ë˜ìŠ¤
class TherapySimulation:
    def __init__(self, persona_type: str, chat_id: str, user_id: str, max_turns: int = 20):
        self.persona_type = persona_type
        self.chat_id = chat_id
        self.user_id = user_id
        self.max_turns = max_turns
        self.history = []

        user_info = get_user_info(self.user_id)
        if user_info:
            self.name = user_info["name"]
            self.age = user_info["age"]
            self.gender = user_info["gender"]
        else:
            print(f"{self.user_id}ëŠ” ìƒˆë¡œìš´ ì‚¬ìš©ìì…ë‹ˆë‹¤. ì‚¬ìš©ì ì •ë³´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            self.name = input("ì´ë¦„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”: ")
            self.age = int(input("ë‚˜ì´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”: "))
            self.gender = input("ì„±ë³„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”: ")
            save_user_info(self.user_id, self.name, self.age, self.gender)

        chat_log = get_chat_log(self.chat_id)
        if chat_log:
            self.history = chat_log
        else:
            self.history.append({
                "role": "client",
                "message": f"{self.name}ë‹˜, ì•ˆë…•í•˜ì„¸ìš”. ì–´ë–¤ ë¬¸ì œê°€ ìˆìœ¼ì‹ ê°€ìš”?"
            })

        self.subllm_agent = SubLLMAgent()
        self.evaluator_agent = EvaluatorAgent(criteria_list=["general_1", "general_2", "general_3", "cbt_1", "cbt_2", "cbt_3"])
        self.counselor_agent = CounselorAgent(
            client_info=f"{self.name}, {self.age}ì„¸, {self.gender}",
            total_strategy="",
            persona_type=persona_type,
            emotion="",
            distortion=""
        )
        self._init_history()

    def _init_history(self):
        if not self.history:
            self.history.append({
                "role": "client",
                "message": f"{self.name}ë‹˜, ì•ˆë…•í•˜ì„¸ìš”. ì–´ë–¤ ë¬¸ì œê°€ ìˆìœ¼ì‹ ê°€ìš”?"
            })

    def run(self):
        mode = input("ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš” (text/voice): ").strip().lower()
        if mode not in ["text", "voice"]:
            mode = "text"

        for turn in range(self.max_turns):
            print(f"--- Turn {turn + 1} ({mode.upper()} MODE) ---")

            # ìƒë‹´ì ì‘ë‹µ ìƒì„±
            counselor_msg = self.counselor_agent.generate_response(self.history)
            self.history.append({"role": "counselor", "message": counselor_msg})
            print("Counselor:", counselor_msg)

            # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
            if mode == "voice":
                result = record_audio_keypress("input.wav", language="ko", fp16=False)  # ìˆ˜ì •ëœ í•¨ìˆ˜ëŠ” "ok" ë˜ëŠ” "exit" ë°˜í™˜
                if result == "exit":
                    print("ğŸ›‘ Enter í‚¤ë¥¼ 2ì´ˆ ì´ìƒ ëˆŒëŸ¬ ì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                    break
                client_msg = whisper_transcribe("input.wav").strip()
                print(f"{self.name}: {client_msg}")
            else:
                client_msg = input(f"{self.name}: ").strip()

            # ì¢…ë£Œ ëª…ë ¹ì–´ í¬í•¨ ì—¬ë¶€ í™•ì¸
            if any(keyword in client_msg.lower() for keyword in ["ì¢…ë£Œ", "ëë‚´ì", "ê·¸ë§Œí• ë˜"]):
                print("ğŸ›‘ ì¢…ë£Œ ëª…ë ¹ì–´ ê°ì§€ë¨. ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                self.history.append({"role": "client", "message": client_msg})
                break

            self.history.append({"role": "client", "message": client_msg})

            # ê°ì •/ì¸ì§€ì™œê³¡ ë¶„ì„
            analysis_result = self.subllm_agent.analyze(client_msg)
            emotion = analysis_result.get("ê°ì •", "")
            distortion = analysis_result.get("ì¸ì§€ì™œê³¡", "")
            total_strategy = analysis_result.get("ì´í•©_CBTì „ëµ", "")

            print(f"Emotion detected: {emotion}")
            print(f"Cognitive Distortion detected: {distortion}")
            print(f"CBT Strategy: {total_strategy}")
            print()

            # ìƒë‹´ì agent ì—…ë°ì´íŠ¸
            self.counselor_agent = CounselorAgent(
                client_info=f"{self.name}, {self.age}ì„¸, {self.gender}ì„±",
                total_strategy=total_strategy,
                persona_type=self.persona_type,
                emotion=emotion,
                distortion=distortion
            )

            # ë¡œê·¸ ì €ì¥
            save_chat_log(self.user_id, self.chat_id, client_msg, counselor_msg)

        # í‰ê°€
        evaluation_result = self.evaluator_agent.evaluate_all(self.history)
        return {
            "persona": self.persona_type,
            "cbt_strategy": total_strategy,
            "cognitive_distortion": distortion,
            "emotion": emotion,
            "history": self.history,
            "evaluation": evaluation_result
        }


# ì‹¤í–‰
if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("--output_file", required=True)
    parser.add_argument("--persona_type", required=True)
    parser.add_argument("--chat_id", required=True)
    parser.add_argument("--user_id", required=True)
    args = parser.parse_args()

    sim = TherapySimulation(
        persona_type=args.persona_type,
        chat_id=args.chat_id,
        user_id=args.user_id
    )
    result = sim.run()

    Path(args.output_file).parent.mkdir(parents=True, exist_ok=True)
    with open(args.output_file, "w", encoding="utf-8") as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
